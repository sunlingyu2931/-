1. Utf-8 

   又称万国码，8-bit unicode transformation format

   一种针对unicode的可变长度字符编码

   用1-6个字节编码





2. json

   一种数据格式，

   包括三种类型的值：简单值(字符串, 数字, 布尔, null), 对象, 数组





3. 监督学习

   training set 有特征有标签

   testing set 有特征去预测标签





4. 先验概率，后验概率和 条件概率

   先验概率: 

   事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单独事件概率，如P(x),P(y)。

   

   后验概率: 它的获得是在观察到事件Y发生后得到的。（利用已知数据来求）



​       条件概率：

​       一个事件发生后另一个事件发生的概率。一般的形式为P(x|y)表示y发生的条件        下x发生的概率。



5. 极大似然估计 maximum likelihood estimation

   利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。







（区别：P(data; μ, σ) 的意思是「在模型参数μ、σ条件下，观察到数据 data 的概率」）





![Screen Shot 2019-06-19 at 6.21.02 am](/Users/sunlingyu/Desktop/Screen Shot 2019-06-19 at 6.21.02 am.png)

实际中我们经常会把似然函数取log



L(μ, σ; data) 的意思是「我们在观察到一组数据 data 之后，参数μ、σ取特定的值的似然度。」所有的概率相乘



尽管这似然函数和概率数值上是相等的，但从根本上是提出了两个不同的问题——一个是关于数据的，另一个是关于参数值的。









6. 什么是熵？什么是信息？

   熵：当一件事情有多种可能情况时，这件事情对某人而言具体是哪种情况的不确定性叫熵。entropy



​        而能够帮助人们 ###消除### 这种不确定性的事物就是信息

​        不能帮助人们消除不确定性的事物称为数据或者噪音

​        信息是一个物理量，是有单位的bits



​        熵和信息数量相等，意义相反。获取信息意味着消除不确定性，也就等于消除熵



信息与熵的关系：

![Screen Shot 2019-06-19 at 6.19.00 am](/Users/sunlingyu/Desktop/Screen Shot 2019-06-19 at 6.19.00 am.png)



熵是对随机变量的平均的不确定性的度量， 

信息是对某一个具体事件不确定性的度量



（当某件事情概率高的时候，信息量就是比较低的）





